---
title: "FunctQuant R Package"
author: "Reda El Amri"
date: "2018-02-27"
output: github_document
  #html_document: default
  #pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Description

This package contains functions that provide a greedy functional quantization and also the optimal grid (see my paper for more details: **Data-driven stochastic inversion via functional quantization** [<https://link.springer.com/article/10.1007/s11222-019-09888-8>]).

## R functions

```{r echo=FALSE}
CVT <- function(data,size,iter=22)
{
  Nsim <- dim(data)[1]
  discretization <- dim(data)[2]
  id <- sample(seq(1,Nsim,by=1),size)
  center <- data[id,]
  for(j in 1:iter)
  {
    ccenters <- center
    pairs <- (data)
    distances <- outer(
      1:nrow(pairs),
      1:nrow(ccenters),
      Vectorize( function(m,l) {
        sqrt(sum( (pairs[m,] - ccenters[l,])^2 )/discretization)
      } )
    )
    clusters <- apply(distances,1,which.min)
    weight <- rep(0,size)
    for(q in 1:size) weight[q] <- length(which(clusters==q))/Nsim
    for(i in 1:size)
    {
      if( length(which(clusters==i)) > 1) center[i,] <- apply(data[which(clusters==i),],2,mean)
      if( length(which(clusters==i)) == 1) center[i,] <- data[which(clusters==i),]
      if( length(which(clusters==i)) == 0) center[i,] <- center[i,]
    }
    data <- data
  }
  return(list(data=data,quantizer=center,weights=weight))
}
StochGradient <- function(data,mKL,size)
{
  choice.grid_Reda <- function(X, N, ng=1, p = 2) {
    if (!is.numeric(X))
      stop("X must be numeric")
    if (!is.vector(X) & !is.matrix(X))
      stop("X must be a matrix or a vector")
    if ((!(floor(N) == N)) | (N <= 0))
      stop("N must be entire and positive")
    if ((!(floor(ng) == ng)) | (ng <= 0))
      stop("B must be entire")
    if (p < 1)
      stop("p must be at least 1")
    if (is.vector(X)) {
      d <- 1
      n <- length(X)
      primeX <- matrix(sample(X, n * ng, replace = TRUE),
                       nrow = ng)
      hatX <- replicate(ng, sample(unique(X), N, replace = FALSE))
      hatX0 <- hatX  #save the initial grids
      gammaX <- array(0, dim = c(ng, n + 1))
      # initialisation of the step parameter gamma
      a_gamma <- 4 * N
      b_gamma <- pi^2 * N^(-2)
      BtestX = array(Inf, dim = c(ng, 1))
      # choice of gamma0X
      projXbootinit <- array(0, dim = c(n, ng))
      # index of the grid on which X is projected
      iminx <- array(0, dim = c(n, ng))
      for (i in 1:n) {
        RepX <- matrix(rep(X[i], N * ng), ncol = ng, byrow = TRUE)
        Ax <- sqrt((RepX - hatX0)^2)
        iminx[i, ] <- apply(Ax, 2, which.min)
        mx <- matrix(c(iminx[i, ], c(1:ng)), nrow = ng)
        projXbootinit[i, ] <- hatX0[mx]
      }
      RepX <- matrix(rep(X, ng), ncol = ng)
      distortion <- apply((RepX - projXbootinit)^2, 2, sum)/n
      temp_gammaX <- which(distortion > 1)
      if (length(temp_gammaX) > 0) {
        distortion[temp_gammaX] <- array(1, dim = c(length(temp_gammaX),
                                                    1))
      }
      gamma0X <- distortion
      if(any(gamma0X < 0.005)){gamma0X[gamma0X<0.005] <- 1}
      gammaX = array(0, dim = c(ng, n + 1))
      for (i in 1:ng) {
        # calculation of the step parameter
        gammaX[i, ] <- gamma0X[i] * a_gamma/(a_gamma + gamma0X[i] *
                                               b_gamma * c(1:(n + 1) - 1))
      }
      gammaX[, 1] <- gamma0X
      iminX <- array(0, dim = c(n, ng))  #index that will change
      tildeX <- array(0, dim = c(N, ng))
      # updating of the grids, providing optimal grids
      for (i in 1:n) {
        for (j in 1:ng) {
          tildeX[, j] <- matrix(rep(primeX[j, i], N), nrow = N,
                                byrow = TRUE)
        }
        Ax <- sqrt((tildeX - hatX)^2)
        # calculation of each distance to determine the point of
        # the grid the closer of the stimuli
        iminX[i, ] <- apply(Ax, 2, which.min)
        mX <- matrix(c(iminX[i, ], c(1:ng)), nrow = ng)
        if(sqrt(sum((hatX[mX] - primeX[, i])^2))==0){
          hatX[mX] <- hatX[mX] - gammaX[, i + 1] * (hatX[mX] - primeX[, i])
        }else{
          hatX[mX] <- hatX[mX] - gammaX[, i + 1] * (hatX[mX] -
                                                      primeX[, i]) * (sqrt(sum((hatX[mX] - primeX[,
                                                                                                  i])^2)))^(p - 1)/sqrt(sum((hatX[mX] - primeX[,                                                                                                                          i])^2))
        }
      }
    } else {
      n <- ncol(X)
      d <- nrow(X)
      primeX <- array(X[, sample(c(1:n), n * ng,
                                 replace = T)], dim = c(d, n, ng))
      hatX <- replicate(ng, unique(X)[, sample(c(1:n),
                                               N, replace = F)])  # initial grids chosen randomly in the sample
      hatX <- array(hatX, dim = c(d, N, ng))
      hatX0 <- hatX  #save the initial grids
      # initialisation of the step parameter gamma
      a_gamma <- 4 * N^(1/d)
      b_gamma <- pi^2 * N^(-2/d)
      BtestX <- array(Inf, dim = c(1, ng))
      # choice of gamma0X
      for (i in 1:(N - 1)) {
        for (j in (i + 1):N) {
          Bx <- array(0, dim = c(ng, 1))
          Bx <- sqrt(apply((hatX[, i, , drop = FALSE] -
                              hatX[, j, , drop = FALSE])^2, c(2, 3), sum))/2
          temp_gammaX <- which(Bx < BtestX)
          BtestX[temp_gammaX] <- Bx[temp_gammaX]
        }
      }
      temp_gammaX = which(BtestX > 1)
      if (length(temp_gammaX) > 0) {
        BtestX[temp_gammaX] <- array(1, dim = c(length(temp_gammaX),
                                                1))
      }
      gamma0X <- BtestX
      if(any(gamma0X < 0.005)){gamma0X[gamma0X<0.005] <- 1}
      
      gammaX <- array(0, dim = c(ng, n + 1))
      for (i in 1:ng) {
        # calculation of the step parameter
        gammaX[i, ] <- gamma0X[i] * a_gamma/(a_gamma + gamma0X[i] *
                                               b_gamma * c(1:(n + 1) - 1))
      }
      gammaX[, 1] <- gamma0X
      iminX <- array(0, dim = c(n, ng))  #index that will change
      tildeX <- array(0, dim = c(d, N, ng))
      # updating of the grids, providing optimal grids
      for (i in 1:n) {
        for (j in 1:ng) {
          tildeX[, , j] <- matrix(rep(primeX[, i, j], N),
                                  nrow = N, byrow = FALSE)
        }
        Ax <- sqrt(apply((tildeX - hatX)^2, c(2, 3), sum))
        # calculation of each distance to determine the point of the grid
        #the closer of the stimuli
        iminX[i, ] <- apply(Ax, 2, which.min)
        for (k in 1:d) {
          m <- matrix(c(rep(k, ng), iminX[i, ], c(1:ng)), ncol = 3)
          if(p==2){
            hatX[m] = hatX[m] - gammaX[, i + 1] * (hatX[m] - primeX[k, i, ])
          }else{
            hatX[m] = hatX[m] - gammaX[,i + 1] * (hatX[m] - primeX[k, i, ]) *
              (sqrt(sum((hatX[m] - primeX[k, i, ])^2)))^(p - 1)/sqrt(sum((hatX[m] - primeX[k,
                                                                                           i, ])^2))
          }
        }
      }
    }
    output <- list(init_grid=hatX0,opti_grid=hatX)
    output
  }
  
  dimRed <- Karhunen_Loeve(data,mKL,scale=TRUE)
  support <- dimRed$Coeff
  MEAN <- dimRed$center
  
  l <- choice.grid_Reda(t(support),size,ng=1,p=2)
  
  newCoeff <- t(l$opti_grid[,,1])
  
  quantizer <- matrix(0,ncol=ncol(data),nrow=size)
  for(i in 1:size)
  {
    test <- matrix(0,ncol=mKL,nrow=ncol(data))
    for(j in 1:mKL) test[,j] <- newCoeff[i,j] * (dimRed$eigenfunction[,j]  )
    quantizer[i,] <- apply(test,1,sum) + MEAN
  }
  
  ccenters <- quantizer
  pairs <- data
  distances <- outer(
    1:nrow(pairs),
    1:nrow(ccenters),
    Vectorize( function(m,l) {
      sum( (pairs[m,] - ccenters[l,])^2 )
    } )
  )
  clusters <- apply(distances,1,which.min)
  weight <- as.vector(as.matrix(NA,1,size))
  for(q in 1:size) weight[q] <- length(which(clusters==q))/dim(data)[1]
  
  return(list(data=data,quantizer=quantizer,weights=weight))
}
GFQ <- function(data,mKL,size,method,deepstart=TRUE)
{
  support <- Karhunen_Loeve(data,mKL,scale=TRUE)$Coeff
  if(method == 'L2')
  {
    DESIGN <- NULL
    DESIGN <- as.vector(which.min(apply(((support - colMeans(support))^2),1,sum)))
    n <- dim(support)[1]
    for(j in 2:n)
    {
      e2 <- rep(NA,n)
      for(i in 1:n)
      {
        Distance <- as.matrix(dist(rbind(support,support[c(DESIGN,i),])))
        if(j==1) e2[i] <- min((Distance[1:n,(n+1)])[-i])
        else e2[i] <- sum(apply(Distance[1:n,(n+1):(n+(j))],1,min))
      }
      DESIGN <- c(DESIGN,which.min(e2))
      if(j > size) break
    }
  }
  
  if(method=='maximin')
  {
    if(deepstart==FALSE) res <- sample(seq(1,dim(data)[1]),1)
    else res <- as.vector(which.min(apply(((support - colMeans(support))^2),1,sum)))
    
    x <- support[res,]
    dim <- dim(as.matrix(x))[1]
    n <- size+1
    N <- dim(support)[1]
    support <- cbind(1:N,support)
    dist <- matrix(NA*1:(2*N),ncol=2)
    dist[,1] = c(1:N)
    p <- x
    for(j in 1:(size-1))
    {
      for(i in 1:N)
      {
        Distance <- as.matrix(dist(rbind(p,support[i,c(2:(dim+1))])))
        diag(Distance) <- 1.0E30
        min1 <- apply(Distance,2,min)
        dist[i,2] <- min(min1)
      }
      ind <- dist[order(dist[,2],decreasing=TRUE),1][1]
      p <- rbind(p,support[ind,c(2:(dim+1))])
      res <- c(res,ind)
    }
    DESIGN <- res
  }
  
  ccenters <- data[DESIGN,]
  pairs <- data
  distances <- outer(
    1:nrow(pairs),
    1:nrow(ccenters),
    Vectorize( function(m,l) {
      sum( (pairs[m,] - ccenters[l,])^2 )
    } )
  )
  clusters <- apply(distances,1,which.min)
  weight <- as.vector(as.matrix(NA,1,size))
  for(q in 1:size) weight[q] <- length(which(clusters==q))/dim(data)[1]
  return(list(data=data,quantizer=data[DESIGN,],weights=weight,index=DESIGN))
}
Karhunen_Loeve <- function(data,mKL,scale=TRUE)
{
  dataa <- data
  MEAN <- apply(data,2,mean)
  if(scale== TRUE){ data <- scale((data),center=TRUE,scale=FALSE)}
  else {data <- (data)}
  n <- nrow(data )
  M <- ncol(data )
  COVARIANCE <- t(data ) %*% (data )/n
  ei=eigen(COVARIANCE, symmetric = TRUE)
  q <- mKL
  EIGENVECTORS <- matrix(ei$vectors[, 1:q],ncol=q)
  EIGENVALUES <- ei$values[1:q]
  VAR <- sum(ei$values[1:q])/sum(ei$values)
  COMPONENT1 <- data %*% EIGENVECTORS
  return(list(Coeff=COMPONENT1,ExplainedVar=VAR,center=MEAN,eigenfunction=EIGENVECTORS))
}
BM <- function(N=1000,M=1,x0=0,t0=0,T=1,Dt=NULL)
{
  Dt <- (T - t0)/N
  t <- seq(t0, T, by=Dt)
  res <- data.frame(sapply(1:M,function(i) c(0,cumsum(rnorm(N,mean  =0,sd=sqrt(Dt))))))
  names(res) <- paste("X",1:M,sep="")
  X <- ts(res, start = t0, deltat = Dt)
  return(X)
}
```

You can also embed plots, for example:

```{r echo=TRUE}
data <- t(BM(N = 200 - 1, M = 300))
size <- 3
quant <- CVT(data,size,iter=22)
```
```{r echo=FALSE}
matplot(t(quant$data),type='l',col='grey',xlim=c(0,200),
        xlab="Time (s)",ylab="Functional output",main="Functional Quantization via Centroidal Voronoi Tesselation (CVT)")
for(i in 1:size) lines(quant$quantizer[i,],col=i,lwd=3)
```

```{r echo=TRUE}
mKL <- 2
quant <- StochGradient(data,mKL,size)
```
```{r echo=FALSE}
matplot(t(quant$data),type='l',col='grey',xlim=c(0,200),
        xlab="Time (s)",ylab="Functional output",main="Functional Quantization via with Stochastic Gradient method")
for(i in 1:size) lines(quant$quantizer[i,],col=i,lwd=3)
```

```{r echo=TRUE}
quant <- GFQ(data,mKL,size,method="maximin",deepstart=TRUE)
```
```{r echo=FALSE}
matplot(t(quant$data),type='l',col='grey',xlim=c(0,300),
        xlab="Time (s)",ylab="Functional output",main="Greedy Functional Quantization via maximin method")
for(i in 1:size) lines(quant$quantizer[i,],col=i,lwd=3)
for(i in 1:size)  points(200,quant$quantizer[i,200],pch=19,col=i)
for(i in 1:size)  text(250,quant$quantizer[i,200],labels=paste("weight[",i,"]=",round(quant$weights[i],3),sep=""),col=i)
```

```{r echo=TRUE}
quant <- GFQ(data,mKL,size,method="L2",deepstart=TRUE)
```
```{r echo=FALSE}
matplot(t(quant$data),type='l',col='grey',xlim=c(0,300),
        xlab="Time (s)",ylab="Functional output",main="Greedy Functional Quantization based on the distorsion error")
for(i in 1:size) lines(quant$quantizer[i,],col=i,lwd=3)
for(i in 1:size)  points(200,quant$quantizer[i,200],pch=19,col=i)
for(i in 1:size)  text(250,quant$quantizer[i,200],labels=paste("weight[",i,"]=",round(quant$weights[i],3),sep=""),col=i)
```

